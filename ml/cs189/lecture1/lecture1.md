---
title: CS189/289 Lecture 1: Introduction + ML Problem Framing
date: 2026-01-25 21:48:10
updated: 2026-01-25 21:48:10
tags:
  - ML
  - CS189
  - 课程笔记
---

# CS189/289 Lecture 1: Introduction + ML Problem Framing

- **课件**: https://eecs189.org/fa25/lecture/lec01

---

## 一、课程背景与总体目标

CS189/289 是 UC Berkeley 的核心机器学习课程，目标是在快速变化的 AI/ML 领域中，为学生建立**稳固、可迁移的基础能力**。课程设计强调从“追逐技术”转向“理解原理”，通过统一的数学符号、合理的先修要求，将**数学 → 算法 → 代码 → 实验**连成一条清晰主线。课堂内容将尽量与真实科研问题和前沿应用相连接，使课程产出具备研究与实践价值。

到课程结束，学生应当能够：

* 理解核心机器学习概念与算法，并将数学推导与实际方法对应起来；
* 使用 Python / PyTorch 实现、训练和调试常见模型；
* 设计合理的实验与评估方法，保证结果可复现、负责任；
* 为后续高级课程与科研做好准备。

---

## 二、什么是机器学习（Machine Learning）

**基本思想**：
机器学习是让计算机系统通过数据学习模型，并利用模型进行预测或决策的过程。其核心流程包括：

* **训练（Training）**：使用数据拟合模型；
* **推断（Inference）**：使用训练好的模型进行预测或决策。

机器学习适用于那些**难以用规则精确定义、但容易通过示例进行说明或评估**的问题，例如垃圾邮件识别、人脸检测等。

**AI 与 ML 的关系**：

* 人工智能（AI）是目标：让机器表现出类似人类的智能行为；
* 机器学习（ML）是主要方法；
* 深度学习是 ML 的重要子领域；
* 术语在产业中常被混用，存在明显的营销驱动现象。

---

## 三、相关概念与研究领域区分

* **统计学（Statistics）**：强调从数据中学习，注重概率建模与理论推导；
* **数据科学（Data Science）**：更偏工程，涵盖数据采集、清洗、分布式计算、系统搭建；
* **机器学习（Machine Learning）**：关注模型与算法，如监督学习、无监督学习、表示学习；
* **人工智能（Artificial Intelligence）**：更宽泛，包含 ML、逻辑推理、规划、感知、机器人等；
* **数据挖掘（Data Mining）**：偏应用与大规模系统；
* **大数据（Big Data）**：强调数据规模与计算基础设施。

---

## 四、监督学习示例：二分类问题

**问题设定（饮料口味预测）**：

* **输入（特征）**：酸度 \(A\)、甜度 \(S\) 等；
* **输出（标签）**：是否 “Great taste”（1/0）。

$$
(x_i, y_i),\quad x_i = (A, S),\quad y_i \in \{0,1\}
$$

**任务类型（由标签空间决定）**：

$$
y \in \{0,1\} \Rightarrow \text{Binary classification},\quad
y \in \{1,\dots,K\} \Rightarrow \text{Multi-class classification},\quad
y \in \mathbb{R} \Rightarrow \text{Regression}
$$

**术语对齐**：

* features 也常叫 covariates / regressors；
* 部分文献里 factor 更偏离散特征。

**模型直觉：查找表 vs 可泛化模型**：

查找表的做法是把训练集中见过的 \((A,S)\) 直接映射到 \(y\)。它更像“记忆”而非“学习”，因此泛化很弱：

* **连续特征命中率低**：需要“完全相等”的输入，新样本几乎不会落在训练点上；
* **缺少结构共享**（inductive bias ≈ 0）：每个样本一条规则，无法抽象出可复用规律；
* **规模/维度不友好**：样本数或特征维度上升时，存储与维护成本迅速膨胀；
* **典型现象**：训练误差可很低甚至为 0，但测试集很差（memorization / 过拟合）。

因此需要能表达“结构”的模型（并通过结构实现泛化），例如：

* **决策树**：用阈值（不等式）把特征空间切成若干区域，每个叶子对应一个区域的预测（空间划分 + 规则共享）。
* **线性分类器**：用一条直线/超平面作为决策边界（例如感知机、逻辑回归的决策边界）。

从表达能力角度，查找表可以视为“极端退化”的树：用等号把空间切到每个训练点一个叶子；而课程语境的决策树强调共享阈值与区域覆盖，因此复杂度可控且能泛化。

---

## 五、训练集、测试集与泛化问题

机器学习的目标是**预测未来，而非记住过去**。
即使一个模型在训练集上达到 100% 准确率，也可能在新数据上表现极差。

课程构造了一个“坏模型”示例：

* 模型仅记忆训练集中出现过的样本；
* 对未见样本统一输出固定值；
* 该模型训练误差为 0，但泛化能力极差。

由此引出 **Occam 剃刀原则**：在解释数据能力相当的情况下，**应优先选择更简单的模型**。

---

## 六、机器学习问题的判定

问题类型区分：

* **工程问题**：可用明确规则直接实现；
* **机器学习问题**：难以规则化，但易于示例化和评估；
* **人类问题**：难以形式化，需要人类判断。

现实系统通常需要三者结合。垃圾邮件识别与对话系统（如 ChatGPT）是典型 ML 问题：可以展示和评价结果，但难以用规则编程实现。

---

## 七、三大学习范式

* **监督学习**：基于 (X, Y) 对，进行分类或回归；
* **无监督学习**：仅有 (X)，用于聚类、降维、密度估计；
* **强化学习**：通过奖励信号学习决策策略（本课程不重点覆盖）。

---

## 八、机器学习发展简史

* 1950s–60s：感知机、早期神经网络；
* 1970s–80s：决策树、强化学习基础；
* 1990s：统计学习理论兴起；
* 2000s：大数据与数据挖掘；
* 2010s：深度学习突破；
* 近年：生成式模型、大语言模型与视觉模型。

---

## 九、机器学习生命周期（ML Lifecycle）

完整流程包括四个阶段：

1. **问题定义（Learning Problem）**：明确预测目标、评价指标、数据来源；
2. **模型设计（Model Design）**：选择模型家族、假设空间与归纳偏置；
3. **优化（Optimization）**：定义损失函数，选择优化算法，处理过拟合；
4. **预测与评估（Predict & Evaluate）**：在测试集上评估性能。

课程将采用“从应用反推理论”的方式进行教学，强调问题建模与工程实践。

---

## 十、课程工具与教学安排

* 使用工具：pandas、Matplotlib/Plotly、scikit-learn、PyTorch、HuggingFace、Weights & Biases；
* 作业形式：5 次作业（含工具熟悉与核心应用），允许使用生成式 AI，但要求完全理解提交内容；
* 强调实验管理、代码规范与个人独立完成。


